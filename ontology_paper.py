# -*- coding: utf-8 -*-
"""ontology_paper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15dvkbAeuQ5a3_A1xdXKytxyh3TP3M9XX
"""

pip install torch pandas scikit-learn

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

df = pd.read_csv("/content/synthetic_ontology_dataset.csv")
print(f"Original dataframe shape: {df.shape}")

feature_cols = df.columns[:-2]
target_cols = ["PME", "PME_Calculated"]

X = df[feature_cols].values
y = df[target_cols].values
print(f"X shape: {X.shape}, y shape: {y.shape}")

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_cnn = X_scaled.reshape(-1, 1, 4, 4)
print(f"X_cnn shape: {X_cnn.shape}")

X_train, X_test, y_train, y_test = train_test_split(X_cnn, y, test_size=0.2, random_state=42)

class OntologyDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.float32)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

train_dataset = OntologyDataset(X_train, y_train)
test_dataset = OntologyDataset(X_test, y_test)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32)

class CostEstimatorCNN(nn.Module):
    def __init__(self):
        super(CostEstimatorCNN, self).__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=2, padding=0),
            nn.ReLU(),
            nn.Conv2d(16, 32, kernel_size=2, padding=0),
            nn.ReLU(),
        )


        self.flat_dim = 32 * 2 * 2

        self.fc = nn.Sequential(
            nn.Flatten(),
            nn.Linear(self.flat_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 2)
        )

    def forward(self, x):
        x = self.cnn(x)
        x = self.fc(x)
        return x

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = CostEstimatorCNN().to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)


num_epochs = 30
for epoch in range(num_epochs):
    model.train()
    total_loss = 0
    for X_batch, y_batch in train_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)
        optimizer.zero_grad()
        outputs = model(X_batch)
        loss = criterion(outputs, y_batch)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}")


model.eval()
with torch.no_grad():
    total_loss = 0
    for X_batch, y_batch in test_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)
        outputs = model(X_batch)
        loss = criterion(outputs, y_batch)
        total_loss += loss.item()
    print(f"\nTest Loss: {total_loss/len(test_loader):.4f}")

model.eval()
with torch.no_grad():
    all_targets = []
    all_predictions = []

    for X_batch, y_batch in test_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)
        outputs = model(X_batch)


        all_targets.append(y_batch.cpu().numpy())
        all_predictions.append(outputs.cpu().numpy())


    y_true = np.vstack(all_targets)
    y_pred = np.vstack(all_predictions)


    mse = np.mean((y_true - y_pred) ** 2, axis=0)
    rmse = np.sqrt(mse)
    mae = np.mean(np.abs(y_true - y_pred), axis=0)


    y_mean = np.mean(y_true, axis=0)
    ss_total = np.sum((y_true - y_mean) ** 2, axis=0)
    ss_residual = np.sum((y_true - y_pred) ** 2, axis=0)
    r_squared = 1 - (ss_residual / ss_total)

    print(f"\nTest MSE: {mse}")
    print(f"Test RMSE: {rmse}")
    print(f"Test MAE: {mae}")
    print(f"R-squared: {r_squared}")


    for i, col in enumerate(target_cols):
        print(f"\nPerformance for {col}:")
        print(f"  RMSE: {rmse[i]:.4f}")
        print(f"  MAE: {mae[i]:.4f}")
        print(f"  R¬≤: {r_squared[i]:.4f}")

torch.save(model.state_dict(), "pme_model.pt")

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


class CostEstimatorCNN(nn.Module):
    def __init__(self):
        super(CostEstimatorCNN, self).__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=2),
            nn.ReLU(),
            nn.Conv2d(16, 32, kernel_size=2),
            nn.ReLU()
        )
        self.fc = nn.Sequential(
            nn.Flatten(),
            nn.Linear(32 * 2 * 2, 64),
            nn.ReLU(),
            nn.Linear(64, 2)
        )

    def forward(self, x):
        x = self.cnn(x)
        x = self.fc(x)
        return x


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = CostEstimatorCNN().to(device)
model.load_state_dict(torch.load("pme_model.pt", map_location=device))
model.eval()


data = pd.read_csv("synthetic_ontology_dataset.csv")
X = data.drop(columns=["PME", "PME_Calculated"]).values
y_actual = data[["PME", "PME_Calculated"]].values


scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_cnn = X_scaled.reshape(-1, 1, 4, 4)


X_tensor = torch.tensor(X_cnn, dtype=torch.float32).to(device)


with torch.no_grad():
    y_pred = model(X_tensor).cpu().numpy()


rmse = np.sqrt(mean_squared_error(y_actual, y_pred, multioutput='raw_values'))
mae = mean_absolute_error(y_actual, y_pred, multioutput='raw_values')
r2 = r2_score(y_actual, y_pred, multioutput='raw_values')

print(f"\nüîç Error Metrics:")
print(f"RMSE: PME = {rmse[0]:.4f}, PME_Calculated = {rmse[1]:.4f}")
print(f"MAE : PME = {mae[0]:.4f}, PME_Calculated = {mae[1]:.4f}")
print(f"R¬≤  : PME = {r2[0]:.4f}, PME_Calculated = {r2[1]:.4f}")


fig, axs = plt.subplots(1, 2, figsize=(12, 5))

titles = ['PME', 'PME_Calculated']
for i in range(2):
    axs[i].scatter(y_actual[:, i], y_pred[:, i], alpha=0.7, color='dodgerblue', label='Predicted vs Actual')
    axs[i].plot([y_actual[:, i].min(), y_actual[:, i].max()],
                [y_actual[:, i].min(), y_actual[:, i].max()],
                'r--', label='Ideal Fit (y=x)')
    axs[i].set_title(f'{titles[i]} Prediction\nR¬≤ = {r2[i]:.3f}')
    axs[i].set_xlabel('Actual')
    axs[i].set_ylabel('Predicted')
    axs[i].legend()
    axs[i].grid(True)

plt.tight_layout()
plt.show()

"""Dont Change any Code segment above this !!

"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt


class CostEstimatorCNN(nn.Module):
    def __init__(self):
        super(CostEstimatorCNN, self).__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=2),
            nn.ReLU(),
            nn.Conv2d(16, 32, kernel_size=2),
            nn.ReLU()
        )
        self.fc = nn.Sequential(
            nn.Flatten(),
            nn.Linear(32 * 2 * 2, 64),
            nn.ReLU(),
            nn.Linear(64, 2)
        )

    def forward(self, x):
        x = self.cnn(x)
        x = self.fc(x)
        return x


data = pd.read_csv("/content/synthetic_ontology_dataset.csv")


X = data.drop(columns=["PME", "PME_Calculated"]).values
y_actual = data[["PME", "PME_Calculated"]].values


scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = CostEstimatorCNN().to(device)
model.load_state_dict(torch.load("pme_model.pt", map_location=device))
model.eval()


sample_input = data.drop(columns=["PME", "PME_Calculated"]).mean().values
sample_input_scaled = scaler.transform(sample_input.reshape(1, -1))
sample_input_cnn = sample_input_scaled.reshape(1, 1, 4, 4)
sample_tensor = torch.tensor(sample_input_cnn, dtype=torch.float32).to(device)


with torch.no_grad():
    sample_pred = model(sample_tensor).cpu().numpy()[0]

print("\nüß™ Arbitrary Input Test")
print("Input features (mean of dataset):")
print(sample_input)
print("\nModel Prediction:")
print(f"PME: {sample_pred[0]:.4f}, PME_Calculated: {sample_pred[1]:.4f}")


plt.figure(figsize=(10, 5))
plt.scatter(y_actual[:, 0], y_actual[:, 1], label="Dataset", alpha=0.5, color='gray')
plt.scatter(sample_pred[0], sample_pred[1], color='red', label="Arbitrary Prediction", s=100, edgecolors='black')
plt.xlabel("PME")
plt.ylabel("PME_Calculated")
plt.title("Predicted Point vs Original Data")
plt.grid(True)
plt.legend()
plt.show()

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Define model class
class CostEstimatorCNN(nn.Module):
    def __init__(self):
        super(CostEstimatorCNN, self).__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=2),
            nn.ReLU(),
            nn.Conv2d(16, 32, kernel_size=2),
            nn.ReLU()
        )
        self.fc = nn.Sequential(
            nn.Flatten(),
            nn.Linear(32 * 2 * 2, 64),
            nn.ReLU(),
            nn.Linear(64, 2)
        )

    def forward(self, x):
        x = self.cnn(x)
        x = self.fc(x)
        return x


data = pd.read_csv("/content/synthetic_ontology_dataset.csv")
X = data.drop(columns=["PME", "PME_Calculated"]).values
y_actual = data[["PME", "PME_Calculated"]].values


scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = CostEstimatorCNN().to(device)
model.load_state_dict(torch.load("pme_model.pt", map_location=device))
model.eval()


sample_input = data.drop(columns=["PME", "PME_Calculated"]).mean().values
sample_input_scaled = scaler.transform(sample_input.reshape(1, -1))
sample_input_cnn = sample_input_scaled.reshape(1, 1, 4, 4)
sample_tensor = torch.tensor(sample_input_cnn, dtype=torch.float32).to(device)


with torch.no_grad():
    sample_pred = model(sample_tensor).cpu().numpy()[0]


print("\nüî¢ Arbitrary Input Given to Model (Raw Features):")
print(pd.Series(sample_input, index=data.columns[:-2]))

print("\nüìê Scaled & Reshaped Input Sent to CNN:")
print(sample_input_scaled.reshape(4, 4))

from sklearn.metrics.pairwise import euclidean_distances
distances = euclidean_distances(sample_input_scaled, X_scaled)
closest_idx = np.argmin(distances)
closest_actual = y_actual[closest_idx]

print("\nüéØ Closest Actual PME Pair in Dataset (for simulated error comparison):")
print(f"PME: {closest_actual[0]:.4f}, PME_Calculated: {closest_actual[1]:.4f}")


rmse = np.sqrt(mean_squared_error(closest_actual, sample_pred))
mae = mean_absolute_error(closest_actual, sample_pred)
r2 = r2_score(closest_actual.reshape(1, -1), sample_pred.reshape(1, -1))

print("\nüìâ Error Metrics vs Closest Ground Truth:")
print(f"RMSE: {rmse:.4f}")
print(f"MAE : {mae:.4f}")
print(f"R¬≤  : {r2:.4f}")


plt.figure(figsize=(10, 5))
plt.scatter(y_actual[:, 0], y_actual[:, 1], label="Dataset", alpha=0.4, color='gray')
plt.scatter(sample_pred[0], sample_pred[1], color='red', label="Model Prediction", s=100, edgecolors='black')
plt.scatter(closest_actual[0], closest_actual[1], color='green', label="Closest Actual", s=100, edgecolors='black')
plt.xlabel("PME")
plt.ylabel("PME_Calculated")
plt.title("Model Prediction vs Dataset + Nearest Actual")
plt.grid(True)
plt.legend()
plt.show()